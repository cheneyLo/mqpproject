### MQP meeting September 27

## What we did
* Read some papers
* Learned about deconvolution NNs
* Wrote some of the introduction/related works
  * Did some reading about related topics (fMRIs, NNs, and Viz)

### Misc. Notes
* Stanfords CS231n class lecture (slides) 9 (about CNNs) is relevant for us
* We discussed embedding (dimensional reduction)
* We also discussed different methods of visualizing (deep dream, Gramm matrix, etc...)

## What we plan on doing soon

* Find code & make them work for toy data for different visualizations <br/> Ideally, we'll be able to use the same (famous) model (possibly AlexNet, Google...)<br/>Pick a platform for these models (Caffe, Theano, TensorFlow...)
    - [ ] Patch that causes max activation *start with this*
    - [ ] Deconvolution
    - [ ] Occlusion (in slides)
    - [ ] Deep dream
    - [ ] Embedding?
    - [ ] Other methods

    For each of these:
    - [ ] Code
    - [ ] Model (let's try GoogleNet 4.0)
    - [ ] Data
- [ ] Spend a bit of time as a group going over done research

## By next week

- [ ] Get one model (e.g. GoogleNet)
- [ ] Get some test data
- [ ] Figure out max patch activation
