### Meeting Feb 14

This past week we had issues:

- Training variants takes too long!
  - Fewer epochs is okay, we need to track convergence
    - Our NN, by the nature of its data, we won't be as accurate as, say, alzheimer data
  - We can run things in parallel
- Learning rate calibration issues
  - We're currently doing exponential decay of the learning rate.
  - Standard decay is okay, we can just stop at after a number of iterations
  - Our data are too large to easily overfit...
- Minor coding problems (broke saliency map magick)
- Loosing loss history?
- Ryan doesn't know how to make videos
  - Will just make a bunch of snapshots 1st

##### Next week

##### Week after

##### Last half week
